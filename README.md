# SynthID Text Watermark Detection API

This project provides a FastAPI backend to detect SynthID watermarks in text generated by Large Language Models (LLMs), specifically demonstrated with `meta-llama/Llama-3.2-1B-Instruct`. It uses a trained Bayesian detector from the `synthid-text` library.

## Features

* **Watermark Detection:** `/detect_watermark` endpoint to analyze input text and determine if it contains the configured SynthID watermark using a Bayesian detector.
* **Text Generation (Example):** `/ask` endpoint that generates 4 responses, one of which is randomly watermarked (useful for frontend testing/demonstration).
* **INT4 Quantization:** Uses 4-bit quantization via `bitsandbytes` for faster and more memory-efficient model inference.
* **Utilities:** Includes scripts for training the Bayesian detector, calibrating the detection threshold, and testing accuracy.

## Setup Instructions

1.  **Clone the Repository:**
    ```bash
    git clone https://github.com/amanmprojects/SynthIDEAL.git
    cd SynthIDEAL
    ```

2.  **Create and Activate Virtual Environment:**
    ```bash
    python -m venv .venv
    # On Linux/macOS/WSL
    source .venv/bin/activate
    # On Windows Command Prompt
    # .venv\Scripts\activate.bat
    # On Windows PowerShell
    # .\.venv\Scripts\Activate.ps1
    ```

3.  **Install Requirements:** Ensure you have CUDA installed if using GPU. JAX requires specific CUDA versions, see JAX documentation if issues arise. It's recommended to use Linux/WSL2 for GPU support with JAX.
    ```bash
    pip install -r requirements.txt
    # If needed, install JAX with specific CUDA support, e.g.:
    # pip install -U "jax[cuda12_pip]" -f [https://storage.googleapis.com/jax-releases/jax_cuda_releases.html](https://storage.googleapis.com/jax-releases/jax_cuda_releases.html)
    ```
    *Note: `requirements.txt` should include `synthid-text==0.2.1`, `pandas`, `matplotlib`, `seaborn` in addition to the current ones.*

4.  **Apply Library Patch:** The currently specified `synthid-text==0.2.1` has a bug preventing Bayesian training on GPU. Apply the included patch:
    ```bash
    # Adjust path to site-packages based on your OS/venv structure
    patch -p1 -d .venv/lib/python3.12/site-packages/ < patches/synthid_text_0.2.1_device_check.patch
    # Verify the path before running! Use 'pip show synthid-text' to find location if needed.
    ```

5.  **Set Environment Variables:**
    * Copy the example environment file: `cp .env.example .env`
    * Edit the `.env` file and add your Hugging Face token:
        ```dotenv
        HUGGINGFACE_TOKEN="hf_YOUR_ACTUAL_TOKEN"
        ```

6.  **Obtain Trained Detector:**
    * **Option A (If using Git LFS):** If `bayesian_detector.pkl` is tracked with Git LFS, ensure LFS is installed (`git lfs install`) and pull the file (`git lfs pull`). Place it in the `data/` directory.
    * **Option B (Train yourself):** If the `.pkl` file is not provided, you need to train the detector:
        ```bash
        # This will generate data (cached in training_data_cache.csv) and train the detector
        python scripts/train_bayesian_detector.py
        # This saves bayesian_detector.pkl to the project root, move it to data/
        mv bayesian_detector.pkl data/
        ```
    * *(Ensure the path `TRAINED_DETECTOR_FILE` in `src/api.py` points correctly to `data/bayesian_detector.pkl`)*

## Running the API

Start the FastAPI server using Uvicorn:

```bash
uvicorn src.api:app --reload --host 0.0.0.0 --port 8000
